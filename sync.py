import yaml
import os
import requests
import yt_dlp
import json
import re
import time

import logging

# Setup Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

DOWNLOAD_HISTORY_FILE = "download_history.json"
ID_MAP_FILE = "id_map.json"


CONFIG_FILE = 'config.yaml'

def load_config():
    with open(CONFIG_FILE, 'r') as f:
        return yaml.safe_load(f)

import unicodedata

def normalize_title(s):
    """
    ë¹„êµë¥¼ ìœ„í•´ ë¬¸ìì—´ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.
    íŠ¹ìˆ˜ë¬¸ìë¡œ ì¸í•œ ì°¨ì´(ì˜ˆ: '|' vs 'ï½œ', '/' vs '_')ë¥¼ ë¬´ì‹œí•˜ê¸° ìœ„í•´
    ì•ŒíŒŒë²³, ìˆ«ì, í•œê¸€ ë“± ì£¼ìš” ë¬¸ìë§Œ ë‚¨ê¸°ê³  ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if not s:
        return ""
    
    # 1. ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (NFKC): 'CarraÌ€'(NFD) -> 'CarrÃ '(NFC), 'ğ†'(Bold) -> 'G' ë¡œ í†µì¼
    s = unicodedata.normalize('NFKC', s)
    
    # 2. íŠ¹ìˆ˜ë¬¸ì ì œê±°
    # \w: ì•ŒíŒŒë²³, ìˆ«ì, _, í•œê¸€ ë“±
    # íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜í•˜ì—¬ ë‹¨ì–´ ê²½ê³„ ìœ ì§€
    s = re.sub(r'[^\w\s]', ' ', s) 
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    s = re.sub(r'\s+', ' ', s)
    return s.strip().lower()

def get_playlist_items(playlist_url):
    """
    yt-dlpë¥¼ ì‚¬ìš©í•˜ì—¬ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì˜ í•­ëª©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤ (ë©”íƒ€ë°ì´í„°ë§Œ).
    í•œêµ­ì–´ ë©”íƒ€ë°ì´í„°ë¥¼ ìš°ì„  ìš”ì²­í•©ë‹ˆë‹¤.
    """
    ydl_opts = {
        'extract_flat': True,
        'quiet': True,
        'ignoreerrors': True,
        'http_headers': {
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
        }
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        result = ydl.extract_info(playlist_url, download=False)
        if 'entries' in result:
            return result['entries']
        return []

def get_existing_files(folder_path):
    """
    ë¡œì»¬ í´ë”ì— ìˆëŠ” íŒŒì¼ë“¤ì„ ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë°˜í™˜ê°’: {normalized_name: original_filename}
    """
    if not os.path.exists(folder_path):
        return {}
    
    files = {}
    for f in os.listdir(folder_path):
        # m4a íŒŒì¼ë§Œ ëŒ€ìƒìœ¼ë¡œ í•˜ê±°ë‚˜, ëª¨ë“  íŒŒì¼ì„ ëŒ€ìƒìœ¼ë¡œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        name, _ = os.path.splitext(f)
        norm_name = normalize_title(name)
        files[norm_name] = f
    return files

def send_to_metube(metube_url, video_url, folder_name):
    """
    MeTube APIì— ë‹¤ìš´ë¡œë“œë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
    """
    add_url = f"{metube_url}/add"
    payload = {
        "url": video_url,
        "quality": "best",
        "format": "m4a",
        "folder": folder_name
    }
    
    try:
        response = requests.post(add_url, json=payload)
        response.raise_for_status()
        return True
    except requests.exceptions.RequestException as e:
        print(f"Error sending to MeTube: {e}")
        return False

def load_download_history():
    if not os.path.exists(DOWNLOAD_HISTORY_FILE):
        return []
    try:
        with open(DOWNLOAD_HISTORY_FILE, 'r') as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
            return list(data) # Handle case where file was saved as list but read weirdly, or if strictly needed
    except:
        return []

def save_download_history(history_list):
    with open(DOWNLOAD_HISTORY_FILE, 'w') as f:
        json.dump(history_list, f, indent=4, ensure_ascii=False)

def load_id_map():
    if os.path.exists(ID_MAP_FILE):
        try:
            with open(ID_MAP_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_id_map(id_map):
    with open(ID_MAP_FILE, 'w', encoding='utf-8') as f:
        json.dump(id_map, f, ensure_ascii=False, indent=2)

def is_token_match(normalized_yt_title, existing_norm_name):
    """
    í† í° ê¸°ë°˜ ë§¤ì¹­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    YouTube íƒ€ì´í‹€ì—ì„œ ê´„í˜¸[...] (...) ì•ˆì˜ ë‚´ìš© ì œê±° í›„ í† í°í™”
    """
    # YouTube íƒ€ì´í‹€ì—ì„œ ê´„í˜¸[...] (...) ì•ˆì˜ ë‚´ìš© ì œê±° í›„ í† í°í™”
    title_clean = re.sub(r'\([^)]*\)|\[[^\]]*\]', '', normalized_yt_title)
    normalized_title_clean = normalize_title(title_clean)
    yt_tokens = set(normalized_title_clean.split())
    
    if not yt_tokens:
         yt_tokens = set(normalized_yt_title.split())

    local_tokens = set(existing_norm_name.split())
    
    if len(yt_tokens) > 0 and yt_tokens.issubset(local_tokens):
        return True
    return False

def monitor_downloads(metube_url, expected_items):
    """
    MeTube íˆìŠ¤í† ë¦¬ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ IDë¥¼ íŒŒì¼ëª…ì— ë§¤í•‘í•©ë‹ˆë‹¤.
    expected_items: [{'id': ..., 'title': ..., 'url': ...}]
    """
    if not expected_items:
        return

    expected_ids = [item['id'] for item in expected_items]
    items_info = {item['id']: item for item in expected_items}

    print(f"\n[ëª¨ë‹ˆí„°ë§] {len(expected_ids)}ê°œì˜ í•­ëª© ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
    id_map = load_id_map()
    down_history = load_download_history()
    pending = set(expected_ids)
    
    while pending:
        try:
            resp = requests.get(f"{metube_url}/history", timeout=5)
            if resp.status_code == 200:
                data = resp.json()
                done = data.get('done', [])
                queue = data.get('queue', []) + data.get('pending', [])
                
                # Check for finished items
                found = []
                history_changed = False
                
                for item in done:
                    vid = item.get('id')
                    if vid in pending:
                        filename = item.get('filename') # e.g. "Song.m4a"
                        status = item.get('status')
                        
                        if status == 'error' or item.get('msg') == 'error':
                             error_msg = item.get('error') or 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
                             title = items_info[vid].get('title', 'Unknown Title')
                             print(f"  [ì˜¤ë¥˜] {title} ({vid}): {error_msg}")
                             
                             # Record failure to prevent infinite retries
                             # Using a special prefix to identify failed items
                             failed_mark = f"ERROR: {error_msg}"
                             
                             if vid in id_map:
                                 del id_map[vid]
                             id_map[vid] = failed_mark
                             
                             # Add to history so user can see it failed
                             if vid in down_history:
                                 down_history.remove(vid)
                             down_history.append(vid)
                             
                             found.append(vid)
                             history_changed = True # Save history to show errors
                             continue

                        if filename:
                            # ê²½ë¡œ ì œê±°í•˜ê³  íŒŒì¼ëª…ë§Œ ìœ ì§€
                            # ê²½ë¡œ ì œê±°í•˜ê³  íŒŒì¼ëª…ë§Œ ìœ ì§€
                            filename = os.path.basename(filename)
                            
                            # Update Map & Move to End (Recent)
                            if vid in id_map:
                                del id_map[vid]
                            id_map[vid] = filename
                            
                            title = items_info[vid].get('title', vid)
                            print(f"  [ì™„ë£Œ] {title} -> {filename}")
                            found.append(vid)
                            
                            if vid in down_history:
                                down_history.remove(vid)
                            down_history.append(vid)
                            history_changed = True
                
                for vid in found:
                    pending.remove(vid)
                    
                if found:
                    save_id_map(id_map)
                    
                if history_changed:
                    save_download_history(down_history)
                
                # Check if remaining pending items are actually in queue
                active_ids = {item.get('id') for item in queue}
                
                # Identify lost items (Not in done, Not in queue/pending)
                # They might be failed or cancelled
                lost = [pid for pid in pending if pid not in active_ids]
                for pid in lost:
                    info = items_info.get(pid, {})
                    title = info.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    url = info.get('url', f"https://youtu.be/{pid}")
                    print(f"  [ì‹¤ì¢…] {title} : {url} (ì·¨ì†Œ/ì‹¤íŒ¨ë¨)")
                    pending.remove(pid)
                
                if not pending:
                    print("[ëª¨ë‹ˆí„°ë§] ëª¨ë“  í•­ëª© ì²˜ë¦¬ ì™„ë£Œ.")
                    break
                    
                print(f"  ... {len(pending)}ê°œ ë‚¨ìŒ (ì§„í–‰ ì¤‘: {len([p for p in pending if p in active_ids])})")

            
            time.sleep(3)
        except KeyboardInterrupt:
            print("\n[ëª¨ë‹ˆí„°ë§] ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨.")
            break
        except Exception as e:
            print(f"[ëª¨ë‹ˆí„°ë§] ì˜¤ë¥˜: {e}")
            time.sleep(5)


def sync_id_map_from_metube(metube_url):
    """
    MeTube íˆìŠ¤í† ë¦¬ì—ì„œ ì „ì²´ ê¸°ë¡ì„ ê°€ì ¸ì™€ ë¡œì»¬ id_mapì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    ì´ì „ì— ë‹¤ìš´ë¡œë“œëœ í•­ëª©ë“¤ì˜ ë§¤í•‘ ì •ë³´ë¥¼ ë³µêµ¬í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
    """

    logging.info("MeTube íˆìŠ¤í† ë¦¬ì—ì„œ ID ë§¤í•‘ ë™ê¸°í™” ì¤‘...")
    try:
        logging.info(f"Connecting to MeTube at: {metube_url}/history")
        resp = requests.get(f"{metube_url}/history", timeout=5)
        logging.info(f"MeTube Response Code: {resp.status_code}")
        
        if resp.status_code == 200:
            data = resp.json()
            done = data.get('done', [])
            logging.info(f"Fetched {len(done)} done items from MeTube.")
            
            id_map = load_id_map()
            down_history = load_download_history()
            updated = False
            history_updated = False
            
            for item in done:
                vid = item.get('id')
                filename = item.get('filename')
                if vid and filename:
                    filename = os.path.basename(filename)
                    if vid not in id_map:
                        id_map[vid] = filename
                        updated = True
                        logging.info(f"New history item mapped: {vid} -> {filename}")
                    else:
                        # Existing item: Move to end to mark as 'Recent'
                        del id_map[vid]
                        id_map[vid] = filename
                        updated = True # Force save to persist order change
                    
                    if vid in down_history:
                        down_history.remove(vid)
                    down_history.append(vid)
                    history_updated = True
            
            if updated:
                save_id_map(id_map)
                logging.info(f"íˆìŠ¤í† ë¦¬ì—ì„œ {len(done)}ê°œì˜ í•­ëª©ìœ¼ë¡œ id_map ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
            else:
                logging.info("ID ë§¤í•‘ì´ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
                
            if history_updated:
                save_download_history(down_history)
                logging.info(f"MeTube ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ê¸°ë¡ ë™ê¸°í™” ì™„ë£Œ.")
        else:
            logging.error(f"MeTube responded with error: {resp.text}")
    except Exception as e:
        logging.error(f"id_map ë™ê¸°í™” ì‹¤íŒ¨: {e}")

def main():
    # 1. ì„¤ì • ë¡œë“œ
    config = load_config()
    metube_url = config['metube_url']
    playlists = config['playlists']
    
    # Pre-sync ID map to ensure we have latest filenames
    sync_id_map_from_metube(metube_url)
    
    down_history = load_download_history()
    id_map = load_id_map()
    

    
    total_newly_added = []
    


    for pl in playlists:
        print(f"\ní”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘: {pl['name']}")
        
        # 2. ë¡œì»¬ íŒŒì¼ í™•ì¸
        existing_files_map = get_existing_files(pl['folder']) # {norm_name: real_name}
        existing_filenames = set(existing_files_map.values()) # {real_name}
        
        # 3. í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        try:
            items = get_playlist_items(pl['url'])
            print(f"í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ {len(items)}ê°œì˜ í•­ëª©ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ í•­ëª© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            continue

        # 4. ë‹¤ìš´ë¡œë“œí•  í•­ëª© ì„ ë³„
        items_to_download = []
        for item in items:
            vid = item.get('id')
            title = item.get('title')
            
            if not title:
                continue

            # Check download history (Sent previously)
            if vid in down_history:
                 # We sent it before. It should be in our 'total_newly_added' monitoring list (added at start).
                 # So we just skip sending it again.
                 # MeTube might be downloading it.
                 continue
            
            # Check ID Map first (Most accurate)
            if vid in id_map:
                mapped_filename = id_map[vid]
                # Check if mapped filename exists in folder
                if mapped_filename in existing_filenames:
                    # Already exists with mapped name
                    continue
                # If mapped filename is NOT in folder, we MUST download it (User deleted it)
                # Fall through to download
            
            # Check Normalized Title Match (Legacy check)
            # If ID check failed (id not in map), we check title
            normalized_title = normalize_title(title)
            
            if normalized_title in existing_files_map:
                continue
                
            # Check Substring
            if any(normalized_title in f for f in existing_files_map):
                continue

            # Check Token Match
            if any(is_token_match(normalized_title, f) for f in existing_files_map):
                continue
            
            items_to_download.append(item)

        print(f"ë‹¤ìš´ë¡œë“œí•  í•­ëª© {len(items_to_download)}ê°œë¥¼ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")

        # 5. ë‹¤ìš´ë¡œë“œ ìš”ì²­
        added_count = 0
        total_to_download = len(items_to_download)
        current_batch_items = []
        
        for i, item in enumerate(items_to_download, 1):
            vid = item.get('id')
            title = item.get('title')
            print(f"[{i}/{total_to_download}] ë‹¤ìš´ë¡œë“œ ëŒ€ê¸°ì—´ ì¶”ê°€: {title}")
            
            video_url = item.get('url') or item.get('webpage_url')
            if video_url and not video_url.startswith('http'):
                 video_url = f"https://www.youtube.com/watch?v={video_url}"

            if send_to_metube(metube_url, video_url, pl['metube_folder']):
                added_count += 1
                down_history.add(vid)
                current_batch_items.append({'id': vid, 'title': title, 'url': video_url})
        
        if current_batch_items:
            total_newly_added.extend(current_batch_items)
            save_download_history(down_history)
            
    # 6. Global Monitoring (Monitor all added items across all playlists)
    if total_newly_added:
        monitor_downloads(metube_url, total_newly_added)

if __name__ == "__main__":
    main()
